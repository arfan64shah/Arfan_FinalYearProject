{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415d43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37068 images belonging to 10 classes.\n",
      "Found 18345 images belonging to 10 classes.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24369/3779347635.py:70: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(training_set,\n",
      "2023-05-05 22:59:39.025491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 2.3046 - accuracy: 0.1028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 22:59:49.672582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 12s 111ms/step - loss: 2.3046 - accuracy: 0.1028 - val_loss: 2.2899 - val_accuracy: 0.1388\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 2.1796 - accuracy: 0.1716 - val_loss: 1.9287 - val_accuracy: 0.2200\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 1.8187 - accuracy: 0.2931 - val_loss: 1.5911 - val_accuracy: 0.3819\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 1.6320 - accuracy: 0.3919 - val_loss: 1.6917 - val_accuracy: 0.3819\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 1.3888 - accuracy: 0.4744 - val_loss: 1.5076 - val_accuracy: 0.4338\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 1.2878 - accuracy: 0.5236 - val_loss: 1.2491 - val_accuracy: 0.5431\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 1.2149 - accuracy: 0.5706 - val_loss: 1.3317 - val_accuracy: 0.5312\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 1.1032 - accuracy: 0.6028 - val_loss: 1.0182 - val_accuracy: 0.6319\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 1.0308 - accuracy: 0.6419 - val_loss: 1.1815 - val_accuracy: 0.5950\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.9479 - accuracy: 0.6641 - val_loss: 0.9757 - val_accuracy: 0.6762\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.9651 - accuracy: 0.6653 - val_loss: 0.9539 - val_accuracy: 0.6662\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.8652 - accuracy: 0.6966 - val_loss: 0.9630 - val_accuracy: 0.6438\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.7890 - accuracy: 0.7325 - val_loss: 0.8054 - val_accuracy: 0.7300\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.8129 - accuracy: 0.7181 - val_loss: 1.0212 - val_accuracy: 0.6881\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 11s 107ms/step - loss: 0.8191 - accuracy: 0.7231 - val_loss: 1.0716 - val_accuracy: 0.6456\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.7999 - accuracy: 0.7319 - val_loss: 0.8527 - val_accuracy: 0.6975\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.7128 - accuracy: 0.7591 - val_loss: 0.7685 - val_accuracy: 0.7212\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.7099 - accuracy: 0.7572 - val_loss: 0.6275 - val_accuracy: 0.7912\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.7189 - accuracy: 0.7494 - val_loss: 0.7195 - val_accuracy: 0.7506\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.6847 - accuracy: 0.7701 - val_loss: 1.1349 - val_accuracy: 0.6288\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.6376 - accuracy: 0.7797 - val_loss: 0.8548 - val_accuracy: 0.7300\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.6085 - accuracy: 0.7941 - val_loss: 1.0292 - val_accuracy: 0.6631\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.6263 - accuracy: 0.7878 - val_loss: 0.7838 - val_accuracy: 0.7094\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.6772 - accuracy: 0.7736 - val_loss: 0.4604 - val_accuracy: 0.8356\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.6126 - accuracy: 0.7900 - val_loss: 0.8486 - val_accuracy: 0.7156\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.5967 - accuracy: 0.7925 - val_loss: 0.6255 - val_accuracy: 0.7931\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.5826 - accuracy: 0.7984 - val_loss: 0.5260 - val_accuracy: 0.8012\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.5800 - accuracy: 0.8006 - val_loss: 0.5612 - val_accuracy: 0.8125\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.6118 - accuracy: 0.8000 - val_loss: 0.4118 - val_accuracy: 0.8431\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5458 - accuracy: 0.8203 - val_loss: 0.5343 - val_accuracy: 0.8000\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5329 - accuracy: 0.8216 - val_loss: 0.5725 - val_accuracy: 0.8100\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.5295 - accuracy: 0.8308 - val_loss: 0.4635 - val_accuracy: 0.8494\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.5059 - accuracy: 0.8244 - val_loss: 0.5990 - val_accuracy: 0.7856\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5271 - accuracy: 0.8213 - val_loss: 0.6742 - val_accuracy: 0.7850\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5008 - accuracy: 0.8259 - val_loss: 0.3485 - val_accuracy: 0.8825\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.4821 - accuracy: 0.8456 - val_loss: 0.4815 - val_accuracy: 0.8225\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5009 - accuracy: 0.8319 - val_loss: 0.8097 - val_accuracy: 0.7281\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 0.5410 - accuracy: 0.8225 - val_loss: 0.4776 - val_accuracy: 0.8231\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.5062 - accuracy: 0.8366 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4793 - accuracy: 0.8441 - val_loss: 0.4126 - val_accuracy: 0.8550\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f22382a5cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "J\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from PIL import Image\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential();\n",
    "\n",
    "#input layer\n",
    "#Convolution\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "#Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#third layer\n",
    "model.add(Conv2D(16,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening before going into dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "#Adding the Output Layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compiling the CNN\n",
    "model.compile(optimizer ='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Data/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Data/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 40,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 50)\n",
    "\n",
    "\n",
    "# prediction of the image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/J.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "results = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if results[0][0] == 1:\n",
    "    prediction = 'A'\n",
    "    print(prediction)\n",
    "elif results[0][1] == 2:\n",
    "    prediction = 'B'\n",
    "    print(prediction)\n",
    "elif results[0][2] == 3:\n",
    "    prediction = 'C'\n",
    "    print(prediction)\n",
    "elif results[0][3] == 4:\n",
    "    prediction = 'D'\n",
    "    print(prediction)\n",
    "elif results[0][4] == 5:\n",
    "    prediction = 'E'\n",
    "    print(prediction)\n",
    "elif results[0][5] == 6:\n",
    "    prediction = 'F'\n",
    "    print(prediction)\n",
    "elif results[0][6] == 7:\n",
    "    prediction = 'G'\n",
    "    print(prediction)\n",
    "elif results[0][7] == 8:\n",
    "    prediction = 'H'\n",
    "    print(prediction)\n",
    "elif results[0][8] == 9:\n",
    "    prediction = 'I'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'J'\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68ecd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (1395762466.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pickle\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "# Save the trained model as a pickle string. \n",
    "\n",
    "with open ('model','wb') as f:\n",
    "\n",
    "     pickle.dump(model,f)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0459308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('multi_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2f08c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (1879384543.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import pickle\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cde751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
