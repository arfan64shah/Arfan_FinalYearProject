{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37068 images belonging to 10 classes.\n",
      "Found 18345 images belonging to 10 classes.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9267/966745523.py:70: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(training_set,\n",
      "2023-05-06 21:24:51.779203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 2.2219 - accuracy: 0.1450"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 21:25:02.513262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 12s 109ms/step - loss: 2.2219 - accuracy: 0.1450 - val_loss: 2.0936 - val_accuracy: 0.2512\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 1.9685 - accuracy: 0.2653 - val_loss: 1.6998 - val_accuracy: 0.3769\n",
      "Epoch 3/40\n",
      " 87/100 [=========================>....] - ETA: 1s - loss: 1.6676 - accuracy: 0.3660"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from PIL import Image\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential();\n",
    "\n",
    "#input layer\n",
    "#Convolution\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "#Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#third layer\n",
    "model.add(Conv2D(16,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening before going into dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "#Adding the Output Layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compiling the CNN\n",
    "model.compile(optimizer ='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Multi_Data/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Multi_Data/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 40,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 50)\n",
    "\n",
    "\n",
    "# prediction of the image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/J.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "results = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if results[0][0] == 1:\n",
    "    prediction = 'A'\n",
    "    print(prediction)\n",
    "elif results[0][1] == 2:\n",
    "    prediction = 'B'\n",
    "    print(prediction)\n",
    "elif results[0][2] == 3:\n",
    "    prediction = 'C'\n",
    "    print(prediction)\n",
    "elif results[0][3] == 4:\n",
    "    prediction = 'D'\n",
    "    print(prediction)\n",
    "elif results[0][4] == 5:\n",
    "    prediction = 'E'\n",
    "    print(prediction)\n",
    "elif results[0][5] == 6:\n",
    "    prediction = 'F'\n",
    "    print(prediction)\n",
    "elif results[0][6] == 7:\n",
    "    prediction = 'G'\n",
    "    print(prediction)\n",
    "elif results[0][7] == 8:\n",
    "    prediction = 'H'\n",
    "    print(prediction)\n",
    "elif results[0][8] == 9:\n",
    "    prediction = 'I'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'J'\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68ecd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# # Save the trained model as a pickle string. \n",
    "\n",
    "# with open ('model','wb') as f:\n",
    "\n",
    "#      pickle.dump(model,f)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0459308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('multi_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d0c9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:09:15.220216: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_2/bias/Assign' id:169 op device:{requested: '', assigned: ''} def:{{{node dense_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_2/bias, dense_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:09:15.981470: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_4/Softmax' id:232 op device:{requested: '', assigned: ''} def:{{{node dense_4/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_4/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-05-06 15:09:16.023707: W tensorflow/c/c_api.cc:300] Operation '{name:'total/Assign' id:311 op device:{requested: '', assigned: ''} def:{{{node total/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total, total/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Graph\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model_graph = Graph()\n",
    "\n",
    "\n",
    "with model_graph.as_default():\n",
    "    tf_session = tf.compat.v1.Session()\n",
    "    with tf_session.as_default():\n",
    "        model1=load_model('multi_CNN.h5')\n",
    "#         model2 = load_model('./models/multi_model.h5')\n",
    "\n",
    "\n",
    "img = image.load_img(\"Data/Single/E.JPG\", target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "with model_graph.as_default():\n",
    "    with tf_session.as_default():\n",
    "        prediction = model1.predict(x, batch_size=10)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1b93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 21:23:22.268040: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 21:23:22.315705: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 21:23:22.316407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 21:23:23.165315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at multi_CNN.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     tf_session \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf_session\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m---> 15\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_CNN.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[1;32m     18\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/Single/A.JPG\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/saving/saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    205\u001b[0m         filepath,\n\u001b[1;32m    206\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    208\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/saving/legacy/save.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         )\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    236\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    237\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at multi_CNN.h5"
     ]
    }
   ],
   "source": [
    "from tensorflow import Graph\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_graph = Graph()\n",
    "\n",
    "with model_graph.as_default():\n",
    "    tf_session = tf.compat.v1.Session()\n",
    "    with tf_session.as_default():\n",
    "        model=load_model('multi_CNN.h5')\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/A.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "with model_graph.as_default():\n",
    "    with tf_session.as_default():\n",
    "        results = model.predict(test_image, batch_size=10)\n",
    "\n",
    "# results = model.predict(test_image)\n",
    "class_labels = training_set.class_indices\n",
    "if results[0][0] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(0)]\n",
    "elif results[0][1] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(1)]\n",
    "elif results[0][2] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(2)]\n",
    "elif results[0][3] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(3)]\n",
    "elif results[0][4] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(4)]\n",
    "elif results[0][5] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(5)]\n",
    "elif results[0][6] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(6)]\n",
    "elif results[0][7] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(7)]\n",
    "elif results[0][8] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(8)]    \n",
    "else:\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(9)]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7db73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
