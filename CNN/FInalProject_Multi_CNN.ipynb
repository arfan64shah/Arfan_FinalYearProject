{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415d43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:20:21.731107: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 14:20:21.782768: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 14:20:21.783381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 14:20:22.608199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37068 images belonging to 10 classes.\n",
      "Found 18345 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20653/3779347635.py:70: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:20:26.235659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 2.1985 - accuracy: 0.1431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:20:40.077478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 16s 152ms/step - loss: 2.1985 - accuracy: 0.1431 - val_loss: 1.9861 - val_accuracy: 0.2163\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 1.8221 - accuracy: 0.3094 - val_loss: 2.2364 - val_accuracy: 0.2819\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 1.5978 - accuracy: 0.4103 - val_loss: 1.4961 - val_accuracy: 0.4344\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 1.4293 - accuracy: 0.4635 - val_loss: 1.7483 - val_accuracy: 0.4081\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 1.2624 - accuracy: 0.5334 - val_loss: 1.5260 - val_accuracy: 0.4781\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 1.1894 - accuracy: 0.5788 - val_loss: 1.2479 - val_accuracy: 0.5294\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 1.0960 - accuracy: 0.5969 - val_loss: 2.7821 - val_accuracy: 0.3713\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 1.0285 - accuracy: 0.6456 - val_loss: 1.6713 - val_accuracy: 0.4869\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.9708 - accuracy: 0.6513 - val_loss: 1.8091 - val_accuracy: 0.4800\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.9013 - accuracy: 0.6878 - val_loss: 0.9068 - val_accuracy: 0.6794\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.8740 - accuracy: 0.6916 - val_loss: 1.3067 - val_accuracy: 0.5656\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.8808 - accuracy: 0.6888 - val_loss: 1.1069 - val_accuracy: 0.6556\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.8501 - accuracy: 0.6975 - val_loss: 0.7699 - val_accuracy: 0.7212\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.7544 - accuracy: 0.7378 - val_loss: 0.9238 - val_accuracy: 0.7013\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.7487 - accuracy: 0.7375 - val_loss: 0.9738 - val_accuracy: 0.6612\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.7190 - accuracy: 0.7428 - val_loss: 1.1260 - val_accuracy: 0.6288\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.7769 - accuracy: 0.7269 - val_loss: 0.7046 - val_accuracy: 0.7487\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.7026 - accuracy: 0.7522 - val_loss: 1.1015 - val_accuracy: 0.6556\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.7155 - accuracy: 0.7528 - val_loss: 1.1675 - val_accuracy: 0.6538\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.6618 - accuracy: 0.7803 - val_loss: 1.4491 - val_accuracy: 0.6187\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6725 - accuracy: 0.7678 - val_loss: 0.7587 - val_accuracy: 0.7487\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.6644 - accuracy: 0.7656 - val_loss: 0.7226 - val_accuracy: 0.7656\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.6171 - accuracy: 0.7853 - val_loss: 0.6700 - val_accuracy: 0.7706\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6048 - accuracy: 0.7897 - val_loss: 0.7940 - val_accuracy: 0.7306\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5949 - accuracy: 0.8009 - val_loss: 1.2842 - val_accuracy: 0.6369\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.6158 - accuracy: 0.7896 - val_loss: 0.5931 - val_accuracy: 0.7856\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5978 - accuracy: 0.8006 - val_loss: 0.9352 - val_accuracy: 0.6913\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5794 - accuracy: 0.7975 - val_loss: 0.5735 - val_accuracy: 0.7881\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5412 - accuracy: 0.8091 - val_loss: 0.6119 - val_accuracy: 0.7825\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 64s 645ms/step - loss: 0.5027 - accuracy: 0.8353 - val_loss: 0.7314 - val_accuracy: 0.7519\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.5735 - accuracy: 0.8044 - val_loss: 1.0250 - val_accuracy: 0.6787\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.6574 - accuracy: 0.7788 - val_loss: 0.4797 - val_accuracy: 0.8294\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.5227 - accuracy: 0.8294 - val_loss: 0.6527 - val_accuracy: 0.7837\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.4970 - accuracy: 0.8316 - val_loss: 0.7399 - val_accuracy: 0.7613\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.5675 - accuracy: 0.8244 - val_loss: 0.5421 - val_accuracy: 0.8094\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5287 - accuracy: 0.8263 - val_loss: 0.6942 - val_accuracy: 0.7663\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5097 - accuracy: 0.8241 - val_loss: 0.5994 - val_accuracy: 0.7994\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4827 - accuracy: 0.8328 - val_loss: 0.6064 - val_accuracy: 0.7981\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4692 - accuracy: 0.8469 - val_loss: 0.7120 - val_accuracy: 0.7738\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4787 - accuracy: 0.8469 - val_loss: 0.6121 - val_accuracy: 0.7937\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "J\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from PIL import Image\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential();\n",
    "\n",
    "#input layer\n",
    "#Convolution\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "#Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#third layer\n",
    "model.add(Conv2D(16,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening before going into dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "#Adding the Output Layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compiling the CNN\n",
    "model.compile(optimizer ='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Data/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Data/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 40,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 50)\n",
    "\n",
    "\n",
    "# prediction of the image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/J.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "results = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if results[0][0] == 1:\n",
    "    prediction = 'A'\n",
    "    print(prediction)\n",
    "elif results[0][1] == 2:\n",
    "    prediction = 'B'\n",
    "    print(prediction)\n",
    "elif results[0][2] == 3:\n",
    "    prediction = 'C'\n",
    "    print(prediction)\n",
    "elif results[0][3] == 4:\n",
    "    prediction = 'D'\n",
    "    print(prediction)\n",
    "elif results[0][4] == 5:\n",
    "    prediction = 'E'\n",
    "    print(prediction)\n",
    "elif results[0][5] == 6:\n",
    "    prediction = 'F'\n",
    "    print(prediction)\n",
    "elif results[0][6] == 7:\n",
    "    prediction = 'G'\n",
    "    print(prediction)\n",
    "elif results[0][7] == 8:\n",
    "    prediction = 'H'\n",
    "    print(prediction)\n",
    "elif results[0][8] == 9:\n",
    "    prediction = 'I'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'J'\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68ecd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# # Save the trained model as a pickle string. \n",
    "\n",
    "# with open ('model','wb') as f:\n",
    "\n",
    "#      pickle.dump(model,f)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0459308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('multi_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d0c9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:09:15.220216: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_2/bias/Assign' id:169 op device:{requested: '', assigned: ''} def:{{{node dense_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_2/bias, dense_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:09:15.981470: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_4/Softmax' id:232 op device:{requested: '', assigned: ''} def:{{{node dense_4/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_4/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-05-06 15:09:16.023707: W tensorflow/c/c_api.cc:300] Operation '{name:'total/Assign' id:311 op device:{requested: '', assigned: ''} def:{{{node total/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total, total/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Graph\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model_graph = Graph()\n",
    "\n",
    "\n",
    "with model_graph.as_default():\n",
    "    tf_session = tf.compat.v1.Session()\n",
    "    with tf_session.as_default():\n",
    "        model1=load_model('multi_CNN.h5')\n",
    "#         model2 = load_model('./models/multi_model.h5')\n",
    "\n",
    "\n",
    "img = image.load_img(\"Data/Single/E.JPG\", target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "with model_graph.as_default():\n",
    "    with tf_session.as_default():\n",
    "        prediction = model1.predict(x, batch_size=10)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1b93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 17:50:50.595482: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_4/bias/Assign' id:226 op device:{requested: '', assigned: ''} def:{{{node dense_4/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_4/bias, dense_4/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/home/uca/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-05-06 17:50:51.018282: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_4/Softmax' id:232 op device:{requested: '', assigned: ''} def:{{{node dense_4/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_4/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-05-06 17:50:51.088536: W tensorflow/c/c_api.cc:300] Operation '{name:'total/Assign' id:311 op device:{requested: '', assigned: ''} def:{{{node total/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total, total/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_image, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# results = model.predict(test_image)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_set\u001b[49m\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(results):\n\u001b[1;32m     28\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(class_labels\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;28mlist\u001b[39m(class_labels\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;241m0\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import Graph\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_graph = Graph()\n",
    "\n",
    "with model_graph.as_default():\n",
    "    tf_session = tf.compat.v1.Session()\n",
    "    with tf_session.as_default():\n",
    "        model=load_model('multi_CNN.h5')\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/A.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "with model_graph.as_default():\n",
    "    with tf_session.as_default():\n",
    "        results = model.predict(test_image, batch_size=10)\n",
    "\n",
    "# results = model.predict(test_image)\n",
    "class_labels = training_set.class_indices\n",
    "if results[0][0] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(0)]\n",
    "elif results[0][1] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(1)]\n",
    "elif results[0][2] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(2)]\n",
    "elif results[0][3] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(3)]\n",
    "elif results[0][4] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(4)]\n",
    "elif results[0][5] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(5)]\n",
    "elif results[0][6] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(6)]\n",
    "elif results[0][7] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(7)]\n",
    "elif results[0][8] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(8)]    \n",
    "else:\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(9)]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7db73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
