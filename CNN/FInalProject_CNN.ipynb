{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415d43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:20:21.731107: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 14:20:21.782768: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 14:20:21.783381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 14:20:22.608199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37068 images belonging to 10 classes.\n",
      "Found 18345 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20653/3779347635.py:70: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:20:26.235659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 2.1985 - accuracy: 0.1431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 14:20:40.077478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 16s 152ms/step - loss: 2.1985 - accuracy: 0.1431 - val_loss: 1.9861 - val_accuracy: 0.2163\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 1.8221 - accuracy: 0.3094 - val_loss: 2.2364 - val_accuracy: 0.2819\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 1.5978 - accuracy: 0.4103 - val_loss: 1.4961 - val_accuracy: 0.4344\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 1.4293 - accuracy: 0.4635 - val_loss: 1.7483 - val_accuracy: 0.4081\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 1.2624 - accuracy: 0.5334 - val_loss: 1.5260 - val_accuracy: 0.4781\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 1.1894 - accuracy: 0.5788 - val_loss: 1.2479 - val_accuracy: 0.5294\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 1.0960 - accuracy: 0.5969 - val_loss: 2.7821 - val_accuracy: 0.3713\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 1.0285 - accuracy: 0.6456 - val_loss: 1.6713 - val_accuracy: 0.4869\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.9708 - accuracy: 0.6513 - val_loss: 1.8091 - val_accuracy: 0.4800\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.9013 - accuracy: 0.6878 - val_loss: 0.9068 - val_accuracy: 0.6794\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.8740 - accuracy: 0.6916 - val_loss: 1.3067 - val_accuracy: 0.5656\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.8808 - accuracy: 0.6888 - val_loss: 1.1069 - val_accuracy: 0.6556\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.8501 - accuracy: 0.6975 - val_loss: 0.7699 - val_accuracy: 0.7212\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.7544 - accuracy: 0.7378 - val_loss: 0.9238 - val_accuracy: 0.7013\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.7487 - accuracy: 0.7375 - val_loss: 0.9738 - val_accuracy: 0.6612\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.7190 - accuracy: 0.7428 - val_loss: 1.1260 - val_accuracy: 0.6288\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.7769 - accuracy: 0.7269 - val_loss: 0.7046 - val_accuracy: 0.7487\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.7026 - accuracy: 0.7522 - val_loss: 1.1015 - val_accuracy: 0.6556\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.7155 - accuracy: 0.7528 - val_loss: 1.1675 - val_accuracy: 0.6538\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 0.6618 - accuracy: 0.7803 - val_loss: 1.4491 - val_accuracy: 0.6187\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.6725 - accuracy: 0.7678 - val_loss: 0.7587 - val_accuracy: 0.7487\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.6644 - accuracy: 0.7656 - val_loss: 0.7226 - val_accuracy: 0.7656\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.6171 - accuracy: 0.7853 - val_loss: 0.6700 - val_accuracy: 0.7706\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.6048 - accuracy: 0.7897 - val_loss: 0.7940 - val_accuracy: 0.7306\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5949 - accuracy: 0.8009 - val_loss: 1.2842 - val_accuracy: 0.6369\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.6158 - accuracy: 0.7896 - val_loss: 0.5931 - val_accuracy: 0.7856\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5978 - accuracy: 0.8006 - val_loss: 0.9352 - val_accuracy: 0.6913\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5794 - accuracy: 0.7975 - val_loss: 0.5735 - val_accuracy: 0.7881\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5412 - accuracy: 0.8091 - val_loss: 0.6119 - val_accuracy: 0.7825\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 64s 645ms/step - loss: 0.5027 - accuracy: 0.8353 - val_loss: 0.7314 - val_accuracy: 0.7519\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.5735 - accuracy: 0.8044 - val_loss: 1.0250 - val_accuracy: 0.6787\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.6574 - accuracy: 0.7788 - val_loss: 0.4797 - val_accuracy: 0.8294\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.5227 - accuracy: 0.8294 - val_loss: 0.6527 - val_accuracy: 0.7837\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.4970 - accuracy: 0.8316 - val_loss: 0.7399 - val_accuracy: 0.7613\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.5675 - accuracy: 0.8244 - val_loss: 0.5421 - val_accuracy: 0.8094\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.5287 - accuracy: 0.8263 - val_loss: 0.6942 - val_accuracy: 0.7663\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.5097 - accuracy: 0.8241 - val_loss: 0.5994 - val_accuracy: 0.7994\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4827 - accuracy: 0.8328 - val_loss: 0.6064 - val_accuracy: 0.7981\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4692 - accuracy: 0.8469 - val_loss: 0.7120 - val_accuracy: 0.7738\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.4787 - accuracy: 0.8469 - val_loss: 0.6121 - val_accuracy: 0.7937\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "J\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from PIL import Image\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential();\n",
    "\n",
    "#input layer\n",
    "#Convolution\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "#Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#second layer\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#third layer\n",
    "model.add(Conv2D(16,(3,3),input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening before going into dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Full connection\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#another dense layer\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "#Adding the Output Layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compiling the CNN\n",
    "model.compile(optimizer ='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Data/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Data/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 100,\n",
    "                         epochs = 40,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 50)\n",
    "\n",
    "\n",
    "# prediction of the image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/J.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "results = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if results[0][0] == 1:\n",
    "    prediction = 'A'\n",
    "    print(prediction)\n",
    "elif results[0][1] == 2:\n",
    "    prediction = 'B'\n",
    "    print(prediction)\n",
    "elif results[0][2] == 3:\n",
    "    prediction = 'C'\n",
    "    print(prediction)\n",
    "elif results[0][3] == 4:\n",
    "    prediction = 'D'\n",
    "    print(prediction)\n",
    "elif results[0][4] == 5:\n",
    "    prediction = 'E'\n",
    "    print(prediction)\n",
    "elif results[0][5] == 6:\n",
    "    prediction = 'F'\n",
    "    print(prediction)\n",
    "elif results[0][6] == 7:\n",
    "    prediction = 'G'\n",
    "    print(prediction)\n",
    "elif results[0][7] == 8:\n",
    "    prediction = 'H'\n",
    "    print(prediction)\n",
    "elif results[0][8] == 9:\n",
    "    prediction = 'I'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'J'\n",
    "    print(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68ecd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# # Save the trained model as a pickle string. \n",
    "\n",
    "# with open ('model','wb') as f:\n",
    "\n",
    "#      pickle.dump(model,f)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0459308",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('multi_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d0c9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:09:15.220216: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_2/bias/Assign' id:169 op device:{requested: '', assigned: ''} def:{{{node dense_2/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_2/bias, dense_2/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:09:15.981470: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_4/Softmax' id:232 op device:{requested: '', assigned: ''} def:{{{node dense_4/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_4/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-05-06 15:09:16.023707: W tensorflow/c/c_api.cc:300] Operation '{name:'total/Assign' id:311 op device:{requested: '', assigned: ''} def:{{{node total/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total, total/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Graph\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model_graph = Graph()\n",
    "\n",
    "\n",
    "with model_graph.as_default():\n",
    "    tf_session = tf.compat.v1.Session()\n",
    "    with tf_session.as_default():\n",
    "        model1=load_model('multi_CNN.h5')\n",
    "#         model2 = load_model('./models/multi_model.h5')\n",
    "\n",
    "\n",
    "img = image.load_img(\"Data/Single/E.JPG\", target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "with model_graph.as_default():\n",
    "    with tf_session.as_default():\n",
    "        prediction = model1.predict(x, batch_size=10)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1b93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 17:31:01.957378: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_4/bias/Assign' id:226 op device:{requested: '', assigned: ''} def:{{{node dense_4/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_4/bias, dense_4/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/home/uca/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array (test_image)\n\u001b[1;32m     18\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m training_set\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(results):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:1059\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1058\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m-> 1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training_arrays_v1.py:801\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.predict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001b[1;32m    798\u001b[0m x, _, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_standardize_user_data(\n\u001b[1;32m    799\u001b[0m     x, check_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39msteps\n\u001b[1;32m    800\u001b[0m )\n\u001b[0;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training_arrays_v1.py:192\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m _update_sample_weight_mode(model, mode, ins)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Get step function and loop type. As part of building the execution\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# function we recompile the metrics based on the updated\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# sample_weight_mode value.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43m_make_execution_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Prepare validation data. Hold references to the iterator and the input\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# list to properly reinitialize and reuse in multiple validation passes.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m val_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training_arrays_v1.py:620\u001b[0m, in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_distribution_strategy:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distributed_training_utils_v1\u001b[38;5;241m.\u001b[39m_make_execution_function(\n\u001b[1;32m    618\u001b[0m         model, mode\n\u001b[1;32m    619\u001b[0m     )\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_execution_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2372\u001b[0m, in \u001b[0;36mModel._make_execution_function\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function\n\u001b[1;32m   2371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ModeKeys\u001b[38;5;241m.\u001b[39mPREDICT:\n\u001b[0;32m-> 2372\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_predict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2356\u001b[0m, in \u001b[0;36mModel._make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2354\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_function_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(ModeKeys\u001b[38;5;241m.\u001b[39mPREDICT):\n\u001b[0;32m-> 2356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/backend.py:4655\u001b[0m, in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   4649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`updates` argument is not supported during \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4651\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution. You passed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (updates,)\n\u001b[1;32m   4652\u001b[0m     )\n\u001b[1;32m   4653\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m-> 4655\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4657\u001b[0m wrap_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(model_inputs):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/functional.py:159\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m--> 159\u001b[0m         [\n\u001b[1;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/functional.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    159\u001b[0m         [\n\u001b[0;32m--> 160\u001b[0m             \u001b[43mfunctional_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_input_keras_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/functional_utils.py:49\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node_module\u001b[38;5;241m.\u001b[39mis_keras_tensor(tensor):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[38;5;241m.\u001b[39mformat(tensor))\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241m.\u001b[39mis_input\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:443\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    436\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    437\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    438\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124m    from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124m    np_config.enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "from tensorflow import Graph\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_graph = Graph()\n",
    "\n",
    "with model_graph.as_default():\n",
    "    tf_session = tf.compat.v1.Session()\n",
    "    with tf_session.as_default():\n",
    "        model=load_model('multi_CNN.h5')\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img ('Data/Single/A.JPG', target_size= (64, 64))\n",
    "test_image.show()\n",
    "test_image = image.img_to_array (test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "results = model.predict(test_image)\n",
    "class_labels = training_set.class_indices\n",
    "if results[0][0] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(0)]\n",
    "elif results[0][1] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(1)]\n",
    "elif results[0][2] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(2)]\n",
    "elif results[0][3] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(3)]\n",
    "elif results[0][4] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(4)]\n",
    "elif results[0][5] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(5)]\n",
    "elif results[0][6] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(6)]\n",
    "elif results[0][7] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(7)]\n",
    "elif results[0][8] == np.max(results):\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(8)]    \n",
    "else:\n",
    "    prediction = list(class_labels.keys())[list(class_labels.values()).index(9)]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7db73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
