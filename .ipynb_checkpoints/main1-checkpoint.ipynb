{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb57107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "import openpyxl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib \n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from numpy import asarray\n",
    "import scipy\n",
    "from scipy.stats import skew, kurtosis\n",
    "from skimage import io\n",
    "import skimage.measure    \n",
    "import skimage.feature\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    " \n",
    "Image_list = []\n",
    "\n",
    "# Create File\n",
    "outWorkbook = xlsxwriter.Workbook(\"out.xlsx\")\n",
    "outSheet = outWorkbook.add_worksheet()\n",
    "\n",
    "# Write Headers\n",
    "outSheet.write(\"A1\", \"Mean1\")\n",
    "outSheet.write(\"B1\", \"Variance1\")\n",
    "outSheet.write(\"C1\", \"Skewness1\")\n",
    "outSheet.write(\"D1\", \"Kurtosis1\")\n",
    "outSheet.write(\"E1\", \"Contrast1\")\n",
    "outSheet.write(\"F1\", \"Entropy1\")\n",
    "outSheet.write(\"G1\", \"Energy1\")\n",
    "outSheet.write(\"H1\", \"Homo1\")\n",
    "outSheet.write(\"I1\", \"Corre1\")\n",
    "outSheet.write(\"J1\", \"Mean2\")\n",
    "outSheet.write(\"K1\", \"Variance2\")\n",
    "outSheet.write(\"L1\", \"Skewness2\")\n",
    "outSheet.write(\"M1\", \"Kurtosis2\")\n",
    "outSheet.write(\"N1\", \"Contrast2\")\n",
    "outSheet.write(\"O1\", \"Entropy2\")\n",
    "outSheet.write(\"P1\", \"Energy2\")\n",
    "outSheet.write(\"Q1\", \"Homo2\")\n",
    "outSheet.write(\"R1\", \"Corre2\")\n",
    "outSheet.write(\"S1\", \"Mean3\")\n",
    "outSheet.write(\"T1\", \"Variance3\")\n",
    "outSheet.write(\"U1\", \"Skewness3\")\n",
    "outSheet.write(\"V1\", \"Kurtosis3\")\n",
    "outSheet.write(\"W1\", \"Contrast3\")\n",
    "outSheet.write(\"X1\", \"Entropy3\")\n",
    "outSheet.write(\"Y1\", \"Energy3\")\n",
    "outSheet.write(\"Z1\", \"Homo13\")\n",
    "outSheet.write(\"AA1\", \"Corre3\")\n",
    "outWorkbook.close()\n",
    "\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = '/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/data1/*.*'\n",
    "output_dir = '/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/'\n",
    "\n",
    "# Create output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "Image_list = []\n",
    "for filename in glob.glob('/home/uca/Desktop/Undergrad/Arfan_FinalYearProject/data1/*.*'):\n",
    "    im = Image.open(filename)\n",
    "    Image_list.append(im)\n",
    "\n",
    "# Loop over all JPEG files in the input directory\n",
    "for filename in input_dir:\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Load the image\n",
    "        img = cv2.imread(os.path.join(input_dir, filename))\n",
    "        \n",
    "        # Split the image into R,G,B channels\n",
    "        blue, green, red = cv2.split(img)\n",
    "        \n",
    "        # Apply PCA to the red channel\n",
    "        pca = PCA().fit(red)\n",
    "        var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components_red = np.argmax(var >= 0.95) + 1\n",
    "        \n",
    "        # Apply PCA to the green channel\n",
    "        pca = PCA().fit(green)\n",
    "        var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components_green = np.argmax(var >= 0.95) + 1\n",
    "        \n",
    "        # Apply PCA to the blue channel\n",
    "        pca = PCA().fit(blue)\n",
    "        var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components_blue = np.argmax(var >= 0.95) + 1\n",
    "        \n",
    "        # Initialize PCA with the selected number of components\n",
    "        n_components = min(n_components_red, n_components_green, n_components_blue)\n",
    "        pca = PCA(n_components)\n",
    "        \n",
    "        # Apply PCA to the red channel and then apply inverse transform to transformed array\n",
    "        red_transformed = pca.fit_transform(red)\n",
    "        red_inverted = pca.inverse_transform(red_transformed)\n",
    "        \n",
    "        # Apply PCA to the green channel and then apply inverse transform to transformed array\n",
    "        green_transformed = pca.fit_transform(green)\n",
    "        green_inverted = pca.inverse_transform(green_transformed)\n",
    "        \n",
    "        # Apply PCA to the blue channel and then apply inverse transform to transformed array\n",
    "        blue_transformed = pca.fit_transform(blue)\n",
    "        blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "\n",
    "        # Combine the color channels into a compressed image\n",
    "        img_compressed = (np.dstack((blue_inverted, green_inverted, red_inverted))).astype(np.uint8)\n",
    "         \n",
    "        image = np.array(img_compressed)\n",
    "        Image_list.append(image) \n",
    " \n",
    "for i in range(0, len(Image_list)):\n",
    "    Image = Image_list[i]  \n",
    "    image = asarray(Image) \n",
    "    R = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    B = image[:,:,2] \n",
    "     \n",
    "    # Histogram Equalization for Red Channel\n",
    "    R = asarray(R) \n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = R.flatten()\n",
    "    # Histogram Equalization\n",
    "    # show the histogram\n",
    "    pyplot.figure(1)\n",
    "    pyplot.hist(flat, bins=10)\n",
    "\n",
    "    # create our own histogram function\n",
    "    def get_histogram1(R, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram1 = np.zeros(bins)\n",
    "# loop through pixels and sum up counts of pixels\n",
    "        for pixel in R:\n",
    "            histogram1[pixel] += 1\n",
    "    \n",
    "# return our final result\n",
    "        return histogram1\n",
    "# execute our histogram function\n",
    "    hist = get_histogram1(flat, 256)\n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a1):\n",
    "        a1 = iter(a1)\n",
    "        b1 = [next(a1)]\n",
    "        for i in a1:\n",
    "            b1.append(b1[-1] + i)\n",
    "        return np.array(b1)\n",
    "# execute the fn\n",
    "    cs1 = cumsum(hist)\n",
    "\n",
    "# display the result\n",
    "    pyplot.figure(2)\n",
    "    pyplot.plot(cs1)\n",
    "\n",
    "# numerator & denomenator\n",
    "    nj1 = (cs1 - cs1.min()) * 255\n",
    "    N1 = cs1.max() - cs1.min()\n",
    "\n",
    "# re-normalize the cumsum\n",
    "    cs1 = nj1 / N1\n",
    "\n",
    "# cast it back to uint8 since we can't use floating point values in images\n",
    "# pyplot.figure(1)\n",
    "    cs1 = cs1.astype('uint8')\n",
    "\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs1)\n",
    "\n",
    "# get the value from cumulative sum for every index in flat, and set that as img_new\n",
    "    img_new1 = cs1[flat]\n",
    "\n",
    "# put array back into original shape since we flattened it\n",
    "    img_new1 = np.reshape(img_new1, R.shape)\n",
    "\n",
    "# set up side-by-side image display\n",
    "# fig = pyplot.figure(3)\n",
    "# fig.set_figheight(15)\n",
    "# fig.set_figwidth(15)\n",
    "\n",
    "# fig.add_subplot(1,2,1)\n",
    "# pyplot.figure(4)\n",
    "# pyplot.imshow(R, cmap='gray')\n",
    "\n",
    "# display the new image\n",
    "# fig.add_subplot(1,2,2)\n",
    "    pyplot.figure(4)\n",
    "    pyplot.imshow(img_new1, cmap='gray')\n",
    "\n",
    "# pyplot.show(block=True)\n",
    "\n",
    "    R = img_new1\n",
    "\n",
    "\n",
    "  # Histogram Equalization for Red Channel\n",
    "    G = asarray(G) \n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = G.flatten()\n",
    "    # Histogram Equalization\n",
    "    # show the histogram\n",
    "    pyplot.figure(1)\n",
    "    pyplot.hist(flat, bins=10)\n",
    "\n",
    "    # create our own histogram function\n",
    "    def get_histogram2(G, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram2 = np.zeros(bins)\n",
    "# loop through pixels and sum up counts of pixels\n",
    "        for pixel in G:\n",
    "            histogram2[pixel] += 1\n",
    "    \n",
    "# return our final result\n",
    "        return histogram2\n",
    "# execute our histogram function\n",
    "    hist = get_histogram2(flat, 256)\n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a2):\n",
    "        a2 = iter(a2)\n",
    "        b2 = [next(a2)]\n",
    "        for i in a2:\n",
    "            b2.append(b2[-1] + i)\n",
    "        return np.array(b2)\n",
    "# execute the fn\n",
    "    cs2 = cumsum(hist)\n",
    "\n",
    "# display the result\n",
    "    pyplot.figure(2)\n",
    "    pyplot.plot(cs2)\n",
    "\n",
    "# numerator & denomenator\n",
    "    nj2 = (cs2 - cs2.min()) * 255\n",
    "    N2 = cs2.max() - cs2.min()\n",
    "\n",
    "# re-normalize the cumsum\n",
    "    cs2 = nj2 / N2\n",
    "\n",
    "# cast it back to uint8 since we can't use floating point values in images\n",
    "# pyplot.figure(1)\n",
    "    cs2 = cs2.astype('uint8')\n",
    "\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs2)\n",
    "\n",
    "# get the value from cumulative sum for every index in flat, and set that as img_new\n",
    "    img_new2 = cs2[flat]\n",
    "\n",
    "# put array back into original shape since we flattened it\n",
    "    img_new2 = np.reshape(img_new2, G.shape)\n",
    "\n",
    "# set up side-by-side image display\n",
    "# fig = pyplot.figure(3)\n",
    "# fig.set_figheight(15)\n",
    "# fig.set_figwidth(15)\n",
    "\n",
    "# fig.add_subplot(1,2,1)\n",
    "# pyplot.figure(4)\n",
    "# pyplot.imshow(R, cmap='gray')\n",
    "\n",
    "# display the new image\n",
    "# fig.add_subplot(1,2,2)\n",
    "    pyplot.figure(4)\n",
    "    pyplot.imshow(img_new2, cmap='gray')\n",
    "\n",
    "# pyplot.show(block=True)\n",
    "\n",
    "    G = img_new2\n",
    "    \n",
    "    \n",
    "      \n",
    "    # Histogram Equalization for Red Channel\n",
    "    B = asarray(B) \n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = B.flatten()\n",
    "    # Histogram Equalization\n",
    "    # show the histogram\n",
    "    pyplot.figure(1)\n",
    "    pyplot.hist(flat, bins=10)\n",
    "\n",
    "    # create our own histogram function\n",
    "    def get_histogram3(B, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram3 = np.zeros(bins)\n",
    "# loop through pixels and sum up counts of pixels\n",
    "        for pixel in B:\n",
    "            histogram3[pixel] += 1\n",
    "    \n",
    "# return our final result\n",
    "        return histogram3\n",
    "# execute our histogram function\n",
    "    hist = get_histogram3(flat, 256)\n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a3):\n",
    "        a3 = iter(a3)\n",
    "        b3 = [next(a3)]\n",
    "        for i in a3:\n",
    "            b3.append(b3[-1] + i)\n",
    "        return np.array(b3)\n",
    "# execute the fn\n",
    "    cs3 = cumsum(hist)\n",
    "\n",
    "# display the result\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs3)\n",
    "\n",
    "# numerator & denomenator\n",
    "    nj3 = (cs3 - cs3.min()) * 255\n",
    "    N3 = cs3.max() - cs3.min()\n",
    "\n",
    "# re-normalize the cumsum\n",
    "    cs3 = nj3 / N3\n",
    "\n",
    "# cast it back to uint8 since we can't use floating point values in images\n",
    "# pyplot.figure(1)\n",
    "    cs3 = cs3.astype('uint8')\n",
    "\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs3)\n",
    "\n",
    "# get the value from cumulative sum for every index in flat, and set that as img_new\n",
    "    img_new3 = cs3[flat]\n",
    "\n",
    "# put array back into original shape since we flattened it\n",
    "    img_new3 = np.reshape(img_new3, B.shape)\n",
    "\n",
    "# set up side-by-side image display\n",
    "# fig = pyplot.figure(3)\n",
    "# fig.set_figheight(15)\n",
    "# fig.set_figwidth(15)\n",
    "\n",
    "# fig.add_subplot(1,2,1)\n",
    "# pyplot.figure(4)\n",
    "# pyplot.imshow(R, cmap='gray')\n",
    "\n",
    "# display the new image\n",
    "# fig.add_subplot(1,2,2)\n",
    "    pyplot.figure(4)\n",
    "    pyplot.imshow(img_new3, cmap='gray')\n",
    "\n",
    "# pyplot.show(block=True)\n",
    "\n",
    "    B = img_new3\n",
    "    \n",
    "       \n",
    "    # Feature Selection from Red Channel\n",
    "    print (\"Calucation nine Statistical features for Red Channel\")\n",
    "    Mean1 = np.mean(R);\n",
    "    print (Mean1)\n",
    "    Variance1 = np.var(R)\n",
    "    Variance1 = math.sqrt(Variance1)\n",
    "    print(Variance1)\n",
    "    Skewness1=skew(R.reshape(-1))\n",
    "    print (Skewness1)\n",
    "    Kurtosis1=kurtosis(R.reshape(-1))\n",
    "    print (Kurtosis1)\n",
    "    entropy1 = skimage.measure.shannon_entropy(R)\n",
    "    print (entropy1)\n",
    "    R = skimage.img_as_ubyte(R)\n",
    "    g1 = skimage.feature.graycomatrix(R, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Cont1 =skimage.feature.graycoprops(g1, 'contrast')[0][0]\n",
    "    print (Cont1)\n",
    "    Energ1 =skimage.feature.graycoprops(g1, 'energy')[0][0]\n",
    "    print (Energ1)\n",
    "    Homo1=skimage.feature.graycoprops(g1, 'homogeneity')[0][0]\n",
    "    print (Homo1)\n",
    "    Corre1=skimage.feature.graycoprops(g1, 'correlation')[0][0]\n",
    "    print (Corre1)\n",
    "    \n",
    "    \n",
    "    # Feature Selection from Green Channel\n",
    "    print (\"Calculate Statistical Features for Green Channel\")\n",
    "    Mean2 = np.mean(G);\n",
    "    print (Mean2)\n",
    "    Variance2 = np.var(G)\n",
    "    Variance2 = math.sqrt(Variance2)\n",
    "    print(Variance2)\n",
    "    Skewness2=skew(G.reshape(-1))\n",
    "    print (Skewness2)\n",
    "    Kurtosis2=kurtosis(G.reshape(-1))\n",
    "    print (Kurtosis2)\n",
    "    entropy2 = skimage.measure.shannon_entropy(G)\n",
    "    print (entropy2)\n",
    "    G = skimage.img_as_ubyte(G)\n",
    "    g2 = skimage.feature.graycomatrix(G, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Cont2 =skimage.feature.graycoprops(g2, 'contrast')[0][0]\n",
    "    print (Cont2)\n",
    "    Energ2 =skimage.feature.graycoprops(g2, 'energy')[0][0]\n",
    "    print (Energ2)\n",
    "    Homo2=skimage.feature.graycoprops(g2, 'homogeneity')[0][0]\n",
    "    print (Homo2)\n",
    "    Corre2=skimage.feature.graycoprops(g2, 'correlation')[0][0]\n",
    "    print (Corre2)\n",
    "    \n",
    "    #  Feature Selection from Blue Channel\n",
    "    print (\"Calucation  Statistical Features for Blue Channel\")\n",
    "    Mean3 = np.mean(B);\n",
    "    print (Mean3)\n",
    "    Variance3 = np.var(B)\n",
    "    Variance3 = math.sqrt(Variance3)\n",
    "    print(Variance3)\n",
    "    Skewness3=skew(B.reshape(-1))\n",
    "    print (Skewness3)\n",
    "    Kurtosis3=kurtosis(B.reshape(-1))\n",
    "    print (Kurtosis3)\n",
    "    entropy3 = skimage.measure.shannon_entropy(B)\n",
    "    print (entropy3)\n",
    "    B = skimage.img_as_ubyte(B)\n",
    "    g3 = skimage.feature.graycomatrix(B, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Cont3 =skimage.feature.graycoprops(g3, 'contrast')[0][0]\n",
    "    print (Cont3)\n",
    "    Energ3 =skimage.feature.graycoprops(g3, 'energy')[0][0]\n",
    "    print (Energ3)\n",
    "    Homo3=skimage.feature.graycoprops(g3, 'homogeneity')[0][0]\n",
    "    print (Homo3)\n",
    "    Corre3=skimage.feature.graycoprops(g3, 'correlation')[0][0]\n",
    "    print (Corre3)\n",
    "    \n",
    "\n",
    "    print(\"How many Times\" )\n",
    "    print (i)\n",
    "    \n",
    "    # Create File\n",
    "    outWorkbook = xlsxwriter.Workbook(\"out.xlsx\")\n",
    "    outSheet = outWorkbook.add_worksheet()\n",
    "    \n",
    "    # Declare Data\n",
    "    values = [Mean1, Variance1, Skewness1, Kurtosis1,entropy1, Cont1,Energ1, Homo1, Corre1, Mean2, Variance2, Skewness2, Kurtosis2, entropy2, Cont2, Energ2, Homo2, Corre2, Mean3, Variance3, Skewness3, Kurtosis3, entropy3, Cont3, Energ3, Homo3, Corre3 ]\n",
    "    \n",
    "     \n",
    "    # Write data to file\n",
    "    outWorkbook = openpyxl.load_workbook(\"out.xlsx\") \n",
    "    outSheet = outWorkbook.active\n",
    "    outSheet.append(values)\n",
    "\n",
    "    outWorkbook.save(filename=\"out.xlsx\")\n",
    "\n",
    "df = pd.read_excel(\"out.xlsx\")\n",
    "df.to_csv(\"data.csv\")\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('data.csv')\n",
    "dataset1 = pd.read_csv('Labels1.csv')\n",
    "X = dataset.iloc[:, 0:-1].values\n",
    "y = dataset1.iloc[:, -1].values\n",
    "    \n",
    "# Training and Testing Data (divide the data into two part)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "classifier= SVC()\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred= classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "sns.heatmap(cm,annot=True)\n",
    "pyplot.savefig('h.png')\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "import pickle \n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "with open ('classifier_pickle','wb') as f:\n",
    "    pickle.dump(classifier,f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5193222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"The accuracy of the model is \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ddee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
