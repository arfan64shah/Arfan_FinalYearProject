{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44dff70",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Labels1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 450\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Importing the dataset\u001b[39;00m\n\u001b[0;32m    449\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 450\u001b[0m dataset1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLabels1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m X \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m26\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    452\u001b[0m y \u001b[38;5;241m=\u001b[39m dataset1\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Labels1.csv'"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "import openpyxl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib \n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from numpy import asarray\n",
    "import scipy\n",
    "from scipy.stats import skew, kurtosis\n",
    "from skimage import io\n",
    "import skimage.measure    \n",
    "import skimage.feature\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    " \n",
    "Image_list = []\n",
    "\n",
    "# Create File\n",
    "outWorkbook = xlsxwriter.Workbook(\"out.xlsx\")\n",
    "outSheet = outWorkbook.add_worksheet()\n",
    "\n",
    "# Write Headers\n",
    "outSheet.write(\"A1\", \"Mean1\")\n",
    "outSheet.write(\"B1\", \"Variance1\")\n",
    "outSheet.write(\"C1\", \"Skewness1\")\n",
    "outSheet.write(\"D1\", \"Kurtosis1\")\n",
    "outSheet.write(\"E1\", \"Contrast1\")\n",
    "outSheet.write(\"F1\", \"Entropy1\")\n",
    "outSheet.write(\"G1\", \"Energy1\")\n",
    "outSheet.write(\"H1\", \"Homo1\")\n",
    "outSheet.write(\"I1\", \"Corre1\")\n",
    "outSheet.write(\"J1\", \"Mean2\")\n",
    "outSheet.write(\"K1\", \"Variance2\")\n",
    "outSheet.write(\"L1\", \"Skewness2\")\n",
    "outSheet.write(\"M1\", \"Kurtosis2\")\n",
    "outSheet.write(\"N1\", \"Contrast2\")\n",
    "outSheet.write(\"O1\", \"Entropy2\")\n",
    "outSheet.write(\"P1\", \"Energy2\")\n",
    "outSheet.write(\"Q1\", \"Homo2\")\n",
    "outSheet.write(\"R1\", \"Corre2\")\n",
    "outSheet.write(\"S1\", \"Mean3\")\n",
    "outSheet.write(\"T1\", \"Variance3\")\n",
    "outSheet.write(\"U1\", \"Skewness3\")\n",
    "outSheet.write(\"V1\", \"Kurtosis3\")\n",
    "outSheet.write(\"W1\", \"Contrast3\")\n",
    "outSheet.write(\"X1\", \"Entropy3\")\n",
    "outSheet.write(\"Y1\", \"Energy3\")\n",
    "outSheet.write(\"Z1\", \"Homo13\")\n",
    "outSheet.write(\"AA1\", \"Corre3\")\n",
    "outWorkbook.close()\n",
    "\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = 'C:/Users/arfan.shah/Desktop/UCA_Undergrad/Arfan_FinalYearProject/data/nothealthy/*.*'\n",
    "output_dir = 'C:/Users/arfan.shah/Desktop/UCA_Undergrad/Arfan_FinalYearProject/'\n",
    "\n",
    "# Create output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop over all JPEG files in the input directory\n",
    "for filename in input_dir:\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Load the image\n",
    "        img = cv2.imread(os.path.join(input_dir, filename))\n",
    "        \n",
    "        # Split the image into R,G,B channels\n",
    "        blue, green, red = cv2.split(img)\n",
    "        \n",
    "        # Apply PCA to the red channel\n",
    "        pca = PCA().fit(red)\n",
    "        var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components_red = np.argmax(var >= 0.95) + 1\n",
    "        \n",
    "        # Apply PCA to the green channel\n",
    "        pca = PCA().fit(green)\n",
    "        var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components_green = np.argmax(var >= 0.95) + 1\n",
    "        \n",
    "        # Apply PCA to the blue channel\n",
    "        pca = PCA().fit(blue)\n",
    "        var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_components_blue = np.argmax(var >= 0.95) + 1\n",
    "        \n",
    "        # Initialize PCA with the selected number of components\n",
    "        n_components = min(n_components_red, n_components_green, n_components_blue)\n",
    "        pca = PCA(n_components)\n",
    "        \n",
    "        # Apply PCA to the red channel and then apply inverse transform to transformed array\n",
    "        red_transformed = pca.fit_transform(red)\n",
    "        red_inverted = pca.inverse_transform(red_transformed)\n",
    "        \n",
    "        # Apply PCA to the green channel and then apply inverse transform to transformed array\n",
    "        green_transformed = pca.fit_transform(green)\n",
    "        green_inverted = pca.inverse_transform(green_transformed)\n",
    "        \n",
    "        # Apply PCA to the blue channel and then apply inverse transform to transformed array\n",
    "        blue_transformed = pca.fit_transform(blue)\n",
    "        blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "\n",
    "        # Combine the color channels into a compressed image\n",
    "        img_compressed = (np.dstack((blue_inverted, green_inverted, red_inverted))).astype(np.uint8)\n",
    "         \n",
    "        image = np.array(img_compressed)\n",
    "        Image_list.append(image) \n",
    " \n",
    "for i in range(0, len(Image_list)):\n",
    "    Image = Image_list[i]  \n",
    "    image = asarray(Image) \n",
    "    R = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    B = image[:,:,2] \n",
    "     \n",
    "    # Histogram Equalization for Red Channel\n",
    "    R = asarray(R) \n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = R.flatten()\n",
    "    # Histogram Equalization\n",
    "    # show the histogram\n",
    "    pyplot.figure(1)\n",
    "    pyplot.hist(flat, bins=10)\n",
    "\n",
    "    # create our own histogram function\n",
    "    def get_histogram1(R, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram1 = np.zeros(bins)\n",
    "# loop through pixels and sum up counts of pixels\n",
    "        for pixel in R:\n",
    "            histogram1[pixel] += 1\n",
    "    \n",
    "# return our final result\n",
    "        return histogram1\n",
    "# execute our histogram function\n",
    "    hist = get_histogram1(flat, 256)\n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a1):\n",
    "        a1 = iter(a1)\n",
    "        b1 = [next(a1)]\n",
    "        for i in a1:\n",
    "            b1.append(b1[-1] + i)\n",
    "        return np.array(b1)\n",
    "# execute the fn\n",
    "    cs1 = cumsum(hist)\n",
    "\n",
    "# display the result\n",
    "    pyplot.figure(2)\n",
    "    pyplot.plot(cs1)\n",
    "\n",
    "# numerator & denomenator\n",
    "    nj1 = (cs1 - cs1.min()) * 255\n",
    "    N1 = cs1.max() - cs1.min()\n",
    "\n",
    "# re-normalize the cumsum\n",
    "    cs1 = nj1 / N1\n",
    "\n",
    "# cast it back to uint8 since we can't use floating point values in images\n",
    "# pyplot.figure(1)\n",
    "    cs1 = cs1.astype('uint8')\n",
    "\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs1)\n",
    "\n",
    "# get the value from cumulative sum for every index in flat, and set that as img_new\n",
    "    img_new1 = cs1[flat]\n",
    "\n",
    "# put array back into original shape since we flattened it\n",
    "    img_new1 = np.reshape(img_new1, R.shape)\n",
    "\n",
    "# set up side-by-side image display\n",
    "# fig = pyplot.figure(3)\n",
    "# fig.set_figheight(15)\n",
    "# fig.set_figwidth(15)\n",
    "\n",
    "# fig.add_subplot(1,2,1)\n",
    "# pyplot.figure(4)\n",
    "# pyplot.imshow(R, cmap='gray')\n",
    "\n",
    "# display the new image\n",
    "# fig.add_subplot(1,2,2)\n",
    "    pyplot.figure(4)\n",
    "    pyplot.imshow(img_new1, cmap='gray')\n",
    "\n",
    "# pyplot.show(block=True)\n",
    "\n",
    "    R = img_new1\n",
    "\n",
    "\n",
    "  # Histogram Equalization for Red Channel\n",
    "    G = asarray(G) \n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = G.flatten()\n",
    "    # Histogram Equalization\n",
    "    # show the histogram\n",
    "    pyplot.figure(1)\n",
    "    pyplot.hist(flat, bins=10)\n",
    "\n",
    "    # create our own histogram function\n",
    "    def get_histogram2(G, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram2 = np.zeros(bins)\n",
    "# loop through pixels and sum up counts of pixels\n",
    "        for pixel in G:\n",
    "            histogram2[pixel] += 1\n",
    "    \n",
    "# return our final result\n",
    "        return histogram2\n",
    "# execute our histogram function\n",
    "    hist = get_histogram2(flat, 256)\n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a2):\n",
    "        a2 = iter(a2)\n",
    "        b2 = [next(a2)]\n",
    "        for i in a2:\n",
    "            b2.append(b2[-1] + i)\n",
    "        return np.array(b2)\n",
    "# execute the fn\n",
    "    cs2 = cumsum(hist)\n",
    "\n",
    "# display the result\n",
    "    pyplot.figure(2)\n",
    "    pyplot.plot(cs2)\n",
    "\n",
    "# numerator & denomenator\n",
    "    nj2 = (cs2 - cs2.min()) * 255\n",
    "    N2 = cs2.max() - cs2.min()\n",
    "\n",
    "# re-normalize the cumsum\n",
    "    cs2 = nj2 / N2\n",
    "\n",
    "# cast it back to uint8 since we can't use floating point values in images\n",
    "# pyplot.figure(1)\n",
    "    cs2 = cs2.astype('uint8')\n",
    "\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs2)\n",
    "\n",
    "# get the value from cumulative sum for every index in flat, and set that as img_new\n",
    "    img_new2 = cs2[flat]\n",
    "\n",
    "# put array back into original shape since we flattened it\n",
    "    img_new2 = np.reshape(img_new2, G.shape)\n",
    "\n",
    "# set up side-by-side image display\n",
    "# fig = pyplot.figure(3)\n",
    "# fig.set_figheight(15)\n",
    "# fig.set_figwidth(15)\n",
    "\n",
    "# fig.add_subplot(1,2,1)\n",
    "# pyplot.figure(4)\n",
    "# pyplot.imshow(R, cmap='gray')\n",
    "\n",
    "# display the new image\n",
    "# fig.add_subplot(1,2,2)\n",
    "    pyplot.figure(4)\n",
    "    pyplot.imshow(img_new2, cmap='gray')\n",
    "\n",
    "# pyplot.show(block=True)\n",
    "\n",
    "    G = img_new2\n",
    "    \n",
    "    \n",
    "      \n",
    "    # Histogram Equalization for Red Channel\n",
    "    B = asarray(B) \n",
    "    # put pixels in a 1D array by flattening out img array\n",
    "    flat = B.flatten()\n",
    "    # Histogram Equalization\n",
    "    # show the histogram\n",
    "    pyplot.figure(1)\n",
    "    pyplot.hist(flat, bins=10)\n",
    "\n",
    "    # create our own histogram function\n",
    "    def get_histogram3(B, bins):\n",
    "        # array with size of bins, set to zeros\n",
    "        histogram3 = np.zeros(bins)\n",
    "# loop through pixels and sum up counts of pixels\n",
    "        for pixel in B:\n",
    "            histogram3[pixel] += 1\n",
    "    \n",
    "# return our final result\n",
    "        return histogram3\n",
    "# execute our histogram function\n",
    "    hist = get_histogram3(flat, 256)\n",
    "    # create our cumulative sum function\n",
    "    def cumsum(a3):\n",
    "        a3 = iter(a3)\n",
    "        b3 = [next(a3)]\n",
    "        for i in a3:\n",
    "            b3.append(b3[-1] + i)\n",
    "        return np.array(b3)\n",
    "# execute the fn\n",
    "    cs3 = cumsum(hist)\n",
    "\n",
    "# display the result\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs3)\n",
    "\n",
    "# numerator & denomenator\n",
    "    nj3 = (cs3 - cs3.min()) * 255\n",
    "    N3 = cs3.max() - cs3.min()\n",
    "\n",
    "# re-normalize the cumsum\n",
    "    cs3 = nj3 / N3\n",
    "\n",
    "# cast it back to uint8 since we can't use floating point values in images\n",
    "# pyplot.figure(1)\n",
    "    cs3 = cs3.astype('uint8')\n",
    "\n",
    "    pyplot.figure(3)\n",
    "    pyplot.plot(cs3)\n",
    "\n",
    "# get the value from cumulative sum for every index in flat, and set that as img_new\n",
    "    img_new3 = cs3[flat]\n",
    "\n",
    "# put array back into original shape since we flattened it\n",
    "    img_new3 = np.reshape(img_new3, B.shape)\n",
    "\n",
    "# set up side-by-side image display\n",
    "# fig = pyplot.figure(3)\n",
    "# fig.set_figheight(15)\n",
    "# fig.set_figwidth(15)\n",
    "\n",
    "# fig.add_subplot(1,2,1)\n",
    "# pyplot.figure(4)\n",
    "# pyplot.imshow(R, cmap='gray')\n",
    "\n",
    "# display the new image\n",
    "# fig.add_subplot(1,2,2)\n",
    "    pyplot.figure(4)\n",
    "    pyplot.imshow(img_new3, cmap='gray')\n",
    "\n",
    "# pyplot.show(block=True)\n",
    "\n",
    "    B = img_new3\n",
    "    \n",
    "       \n",
    "    # Feature Selection from Red Channel\n",
    "    print (\"Calucation nine Statistical features for Red Channel\")\n",
    "    Mean1 = np.mean(R);\n",
    "    print (Mean1)\n",
    "    Variance1 = np.var(R)\n",
    "    Variance1 = math.sqrt(Variance1)\n",
    "    print(Variance1)\n",
    "    Skewness1=skew(R.reshape(-1))\n",
    "    print (Skewness1)\n",
    "    Kurtosis1=kurtosis(R.reshape(-1))\n",
    "    print (Kurtosis1)\n",
    "    entropy1 = skimage.measure.shannon_entropy(R)\n",
    "    print (entropy1)\n",
    "    R = skimage.img_as_ubyte(R)\n",
    "    g1 = skimage.feature.greycomatrix(R, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Cont1 =skimage.feature.greycoprops(g1, 'contrast')[0][0]\n",
    "    print (Cont1)\n",
    "    Energ1 =skimage.feature.greycoprops(g1, 'energy')[0][0]\n",
    "    print (Energ1)\n",
    "    Homo1=skimage.feature.greycoprops(g1, 'homogeneity')[0][0]\n",
    "    print (Homo1)\n",
    "    Corre1=skimage.feature.greycoprops(g1, 'correlation')[0][0]\n",
    "    print (Corre1)\n",
    "    \n",
    "    \n",
    "    # Feature Selection from Green Channel\n",
    "    print (\"Calculate Statistical Features for Green Channel\")\n",
    "    Mean2 = np.mean(G);\n",
    "    print (Mean2)\n",
    "    Variance2 = np.var(G)\n",
    "    Variance2 = math.sqrt(Variance2)\n",
    "    print(Variance2)\n",
    "    Skewness2=skew(G.reshape(-1))\n",
    "    print (Skewness2)\n",
    "    Kurtosis2=kurtosis(G.reshape(-1))\n",
    "    print (Kurtosis2)\n",
    "    entropy2 = skimage.measure.shannon_entropy(G)\n",
    "    print (entropy2)\n",
    "    G = skimage.img_as_ubyte(G)\n",
    "    g2 = skimage.feature.greycomatrix(G, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Cont2 =skimage.feature.greycoprops(g2, 'contrast')[0][0]\n",
    "    print (Cont2)\n",
    "    Energ2 =skimage.feature.greycoprops(g2, 'energy')[0][0]\n",
    "    print (Energ2)\n",
    "    Homo2=skimage.feature.greycoprops(g2, 'homogeneity')[0][0]\n",
    "    print (Homo2)\n",
    "    Corre2=skimage.feature.greycoprops(g2, 'correlation')[0][0]\n",
    "    print (Corre2)\n",
    "    \n",
    "    #  Feature Selection from Blue Channel\n",
    "    print (\"Calucation  Statistical Features for Blue Channel\")\n",
    "    Mean3 = np.mean(B);\n",
    "    print (Mean3)\n",
    "    Variance3 = np.var(B)\n",
    "    Variance3 = math.sqrt(Variance3)\n",
    "    print(Variance3)\n",
    "    Skewness3=skew(B.reshape(-1))\n",
    "    print (Skewness3)\n",
    "    Kurtosis3=kurtosis(B.reshape(-1))\n",
    "    print (Kurtosis3)\n",
    "    entropy3 = skimage.measure.shannon_entropy(B)\n",
    "    print (entropy3)\n",
    "    B = skimage.img_as_ubyte(B)\n",
    "    g3 = skimage.feature.greycomatrix(B, [1], [0], levels=256, symmetric=False, normed=True)\n",
    "    Cont3 =skimage.feature.greycoprops(g3, 'contrast')[0][0]\n",
    "    print (Cont3)\n",
    "    Energ3 =skimage.feature.greycoprops(g3, 'energy')[0][0]\n",
    "    print (Energ3)\n",
    "    Homo3=skimage.feature.greycoprops(g3, 'homogeneity')[0][0]\n",
    "    print (Homo3)\n",
    "    Corre3=skimage.feature.greycoprops(g3, 'correlation')[0][0]\n",
    "    print (Corre3)\n",
    "    \n",
    "\n",
    "    print(\"How many Times\" )\n",
    "    print (i)\n",
    "    \n",
    "    # Create File\n",
    "    outWorkbook = xlsxwriter.Workbook(\"out.xlsx\")\n",
    "    outSheet = outWorkbook.add_worksheet()\n",
    "    \n",
    "    # Declare Data\n",
    "    values = [Mean1, Variance1, Skewness1, Kurtosis1,entropy1, Cont1,Energ1, Homo1, Corre1, Mean2, Variance2, Skewness2, Kurtosis2, entropy2, Cont2, Energ2, Homo2, Corre2, Mean3, Variance3, Skewness3, Kurtosis3, entropy3, Cont3, Energ3, Homo3, Corre3 ]\n",
    "    \n",
    "     \n",
    "    # Write data to file\n",
    "    outWorkbook = openpyxl.load_workbook(\"out.xlsx\") \n",
    "    outSheet = outWorkbook.active\n",
    "    outSheet.append(values)\n",
    "\n",
    "    outWorkbook.save(filename=\"out.xlsx\")\n",
    "\n",
    "df = pd.read_excel(\"out.xlsx\")\n",
    "df.to_csv(\"data.csv\")\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('data.csv')\n",
    "dataset1 = pd.read_csv('Labels1.csv')\n",
    "X = dataset.iloc[:, 0:26].values\n",
    "y = dataset1.iloc[:, 0].values\n",
    "    \n",
    "# Training and Testing Data (divide the data into two part)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred= classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "sns.heatmap(cm,annot=True)\n",
    "pyplot.savefig('h.png')\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "import pickle \n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "with open ('classifier_pickle','wb') as f:\n",
    "    pickle.dump(classifier,f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c2976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
